{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deffining our initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    w_h = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(w_h)\n",
    "def bias_variable(shape):\n",
    "    b_h = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deffining useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(Input, Weights):\n",
    "    return tf.nn.conv2d(Input, Weights, strides = [1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "def max_pool_2x2(Input):\n",
    "    return tf.nn.max_pool(Input, ksize = [1, 2, 2, 1],\n",
    "                         strides = [1, 2, 2, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_layer(Input, Weights_shape, Bias_shape):\n",
    "    w_conv = weight_variable(Weights_shape)\n",
    "    b_conv = weight_variable(Bias_shape)\n",
    "    h_conv = tf.nn.relu(conv2d(Input, w_conv) + b_conv)\n",
    "    return h_conv, w_conv, b_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inputs = conv output\n",
    "#n_convcaps = 8\n",
    "#n_channels = 32\n",
    "#kernel_size = 9\n",
    "#n_strides = 2\n",
    "#padding = 'valid' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(Input, Weights, n_strides=2, padding='SAME'):\n",
    "    return tf.nn.conv2d(Input, Weights, strides = [1, n_strides, n_strides, 1], padding=padding)\n",
    "def max_pool_2x2(Input):\n",
    "    return tf.nn.max_pool(Input, ksize = [1, 2, 2, 1],\n",
    "                         strides = [1, 2, 2, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_layer(Input, Weights_shape, Bias_shape, n_strides, padding, activation=True):\n",
    "    w_conv = weight_variable(Weights_shape)\n",
    "    b_conv = weight_variable(Bias_shape)\n",
    "    if activation == True:\n",
    "        h_conv = tf.nn.relu(conv2d(Input, w_conv, n_strides, padding) + b_conv)\n",
    "    else:\n",
    "        h_conv = conv2d(Input, w_conv, n_strides, padding) + b_conv\n",
    "    return h_conv, w_conv, b_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Primary_caps(nn_batch,Inputs, n_convcaps, n_channels, kernel_size, n_strides, padding):\n",
    "    h_conv, W_conv, b_conv = cnn_layer(Inputs, kernel_size, [n_convcaps*n_channels], n_strides, padding, activation='False')\n",
    "    q=tf.shape(Inputs)\n",
    "    caps_outs = tf.reshape(h_conv, (nn_batch,-1 , n_convcaps))#(Inputs.shape[0], -1 , n_convcaps))\n",
    "    #caps_outs = tf.reshape(h_conv, [(Inputs.shape)[0], -1, n_convcaps])\n",
    "    return h_conv, caps_outs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squashing_func(vector, axis=-1):\n",
    "    sq_norm = tf.reduce_sum(tf.square(vector),0, keep_dims=True);\n",
    "    first_eq = sq_norm/(1+sq_norm);\n",
    "    second_eq = vector / tf.sqrt(sq_norm);\n",
    "    return first_eq*second_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digcaps(Input, o_size, v_len):\n",
    "    print Input.shape\n",
    "    r_Input = tf.reshape(Input, [(Input.shape)[0], -1, 1, (Input.shape)[2]])\n",
    "    b_I = tf.constant(np.zeros([1, Input.shape[1].value, o_size, 1], dtype=np.float32))\n",
    "    print r_Input.shape, b_I.shape\n",
    "    W = weight_variable([1, 1152, 10, 8, 16])\n",
    "    print W.shape\n",
    "    t_Input = tf.tile(Input,[1, 1, 10])\n",
    "    W= tf.tile(W, [Input.shape[0], 1, 1, 1, 1])\n",
    "    print t_Input.shape\n",
    "    print W.shape\n",
    "    return r_Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 16) (50, 28, 28, 1)\n",
      "Input image shape (50, 784)\n",
      "Input label shape (50, 10)\n",
      "Output of first convolutional layer shape (50, 20, 20, 256)\n",
      "Output of the first layer (50, 6, 6, 256)\n",
      "Reshaped output of the first layer (50, 1152, 8)\n",
      "squashed output of the first layer (50, 1152, 8)\n",
      "bias for the routing (1, 1152, 10, 1, 1)\n",
      "weight for routing (50, 1152, 10, 8, 16)\n",
      "expanded inputs (50, 1152, 1, 8, 1)\n",
      "expand the inputs for the 10 outputs (50, 1152, 10, 8, 1)\n",
      "u_hat (50, 1152, 10, 16, 1)\n",
      "softmax shape (50, 1152, 10, 1, 1)\n",
      "after routing shape (50, 10, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "nn_batch = 50;\n",
    "nn_routing = 3;\n",
    "cfg = tf.app.flags.FLAGS\n",
    "tf.Session.reset\n",
    "with tf.device('/gpu:1'): #or '/cpu:0' for cpu only\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])    \n",
    "    h_conv1, W_conv1, b_conv1 = cnn_layer(x_image, [9, 9, 1, 256], [256], 1, padding='VALID')\n",
    "    #h_conv, W_conv, b_conv = cnn_layer(h_conv1, [9, 9, 256, 32*8], [32*8], 2, padding='VALID', activation='False')\n",
    "    h_pout, prim_caps = Primary_caps(nn_batch, h_conv1, 8, 32, [9, 9, 256, 32*8], 2,padding='VALID')\n",
    "    primarycps_s= squashing_func(prim_caps);\n",
    "    #digitCaps = digcaps(primarycaps_squashed, 10, 16);\n",
    "    #h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    #b_ij = tf.constant(0, shape = [1, 10, 10, 1,1])\n",
    "    #c = tf.nn.softmax(b_ij, dim =2)\n",
    "    #print primarycps_s.shape[-2].value\n",
    "    primarycps_s2 = tf.reshape(primarycps_s, shape=(nn_batch, -1, 1, primarycps_s.shape[-1].value))\n",
    "    #print primarycps_s2\n",
    "    bs = tf.constant(np.zeros([1, 1152, 10, 1, 1], dtype=np.float32))\n",
    "    W = weight_variable([1, 1152, 10, 8, 16])\n",
    "    W = tf.tile(W, [nn_batch, 1, 1, 1, 1])\n",
    "    \n",
    "    inputs_expanded = tf.expand_dims(tf.expand_dims(primarycps_s, 3), 2)\n",
    "    primarycps_s3 = tf.tile(inputs_expanded, [1, 1, 10, 1, 1])\n",
    "    \n",
    "    u_hat = tf.matmul(W, primarycps_s3, transpose_a=True)\n",
    "    \n",
    "    for r in range(nn_routing):\n",
    "        sft_max = tf.nn.softmax(bs, dim=2)\n",
    "        sft_max = tf.tile(sft_max, [nn_batch, 1, 1,1, 1])\n",
    "        mlt_sft_hat = tf.multiply(sft_max, u_hat)\n",
    "        mlt_sft_hat = tf.reduce_sum(mlt_sft_hat, axis=1, keep_dims=True)\n",
    "        squash_mlt = squashing_func(mlt_sft_hat)\n",
    "        \n",
    "        squash_mlt_r = tf.tile(squash_mlt, [1, 1152, 1, 1, 1])\n",
    "        u_hat_v = tf.matmul(u_hat, squash_mlt_r, transpose_a=True)\n",
    "        \n",
    "        bs += tf.reduce_sum(u_hat_v, axis=0, keep_dims=True)\n",
    "       \n",
    "    \n",
    "    squash_mlt = tf.squeeze(squash_mlt, axis=1)\n",
    "    #Masking\n",
    "    \n",
    "    length_v = tf.sqrt(tf.reduce_sum(tf.square(squash_mlt), axis = 2,\n",
    "                                    keep_dims = True)+1e-9)\n",
    "    \n",
    "    softmax_v = tf.nn.softmax(length_v, dim=1)\n",
    "    argmax_idx = tf.to_int32(tf.argmax(softmax_v, axis = 1))\n",
    "    argmax_idx = tf.reshape(argmax_idx, shape=(nn_batch,))\n",
    "    \n",
    "    if not True:\n",
    "        masked_vector = []\n",
    "        for btch in range(nn_batch):\n",
    "            v = squash_mlt[btch][argmax_idx[btch], :]\n",
    "            masked_vector.append(tf.reshape(v, shape=(1,1,16,1)))\n",
    "        masked_vector = tf.concat(masked_vector, axis=0)\n",
    "        print masked_vector.shape\n",
    "    else:\n",
    "        masked_vector = tf.matmul(tf.squeeze(squash_mlt),\n",
    "                                 tf.reshape(y_, (-1, 10, 1)), transpose_a=True)\n",
    "        length_v = tf.sqrt(tf.reduce_sum(tf.square(squash_mlt), axis=2,\n",
    "                                        keep_dims = True)+1e-9)\n",
    "    #Decoder\n",
    "    vector_j = tf.reshape(masked_vector, shape=(nn_batch, -1))\n",
    "    W_fc1 = weight_variable([16, 512])\n",
    "    b_fc1 = bias_variable([512])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(vector_j, W_fc1) + b_fc1)\n",
    "    \n",
    "    W_fc2 = weight_variable([512, 1024])\n",
    "    b_fc2 = bias_variable([1024])\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "    W_fc3 = weight_variable([1024, 784])\n",
    "    b_fc3 = bias_variable([784])\n",
    "    h_fc3 = tf.nn.sigmoid(tf.matmul(h_fc2, W_fc3) + b_fc3)\n",
    "    \n",
    "    recons_img = tf.reshape(h_fc3, shape=(nn_batch,28,28,1))\n",
    "    print vector_j.shape, recons_img.shape\n",
    "    #print length_v[0][:], y[0]\n",
    "\n",
    "    with tf.Session(config = tf.ConfigProto(allow_soft_placement = True, log_device_placement = True)) as sess:\n",
    "        \n",
    "        x = mnist.train.images[0:nn_batch]\n",
    "        y = mnist.train.labels[0:nn_batch]\n",
    "        xx = x_image\n",
    "        hh = h_conv1\n",
    "        h_pouts = h_pout\n",
    "        prim = prim_caps\n",
    "        squashed = primarycps_s\n",
    "        bb = bs;\n",
    "        ww = W;\n",
    "        expanded = inputs_expanded\n",
    "        p_s3 = primarycps_s3\n",
    "        mult_u_hat = u_hat\n",
    "        sft_max_s = sft_max \n",
    "        after_routing = squash_mlt\n",
    "        what_is = length_v\n",
    "        #bj = b_ij\n",
    "print \"Input image shape\", x.shape\n",
    "print \"Input label shape\", y.shape\n",
    "print \"Output of first convolutional layer shape\", hh.shape\n",
    "print \"Output of the first layer\", h_pouts.shape\n",
    "print \"Reshaped output of the first layer\", prim.shape\n",
    "print \"squashed output of the first layer\", primarycps_s.shape\n",
    "print \"bias for the routing\", bb.shape\n",
    "print \"weight for routing\", ww.shape\n",
    "print \"expanded inputs\", expanded.shape\n",
    "print \"expand the inputs for the 10 outputs\", p_s3.shape\n",
    "print \"u_hat\", mult_u_hat.shape\n",
    "print \"softmax shape\", sft_max_s.shape\n",
    "print \"after routing shape\", after_routing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "if not True:\n",
    "    print 1\n",
    "else:\n",
    "    print 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
