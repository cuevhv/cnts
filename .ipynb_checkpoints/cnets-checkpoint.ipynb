{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deffining our initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    w_h = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(w_h)\n",
    "def bias_variable(shape):\n",
    "    b_h = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deffining useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(Input, Weights):\n",
    "    return tf.nn.conv2d(Input, Weights, strides = [1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "def max_pool_2x2(Input):\n",
    "    return tf.nn.max_pool(Input, ksize = [1, 2, 2, 1],\n",
    "                         strides = [1, 2, 2, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_layer(Input, Weights_shape, Bias_shape):\n",
    "    w_conv = weight_variable(Weights_shape)\n",
    "    b_conv = weight_variable(Bias_shape)\n",
    "    h_conv = tf.nn.relu(conv2d(Input, w_conv) + b_conv)\n",
    "    return h_conv, w_conv, b_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inputs = conv output\n",
    "#n_convcaps = 8\n",
    "#n_channels = 32\n",
    "#kernel_size = 9\n",
    "#n_strides = 2\n",
    "#padding = 'valid' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(Input, Weights, n_strides=2, padding='SAME'):\n",
    "    return tf.nn.conv2d(Input, Weights, strides = [1, n_strides, n_strides, 1], padding=padding)\n",
    "def max_pool_2x2(Input):\n",
    "    return tf.nn.max_pool(Input, ksize = [1, 2, 2, 1],\n",
    "                         strides = [1, 2, 2, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_layer(Input, Weights_shape, Bias_shape, n_strides, padding, activation=True):\n",
    "    w_conv = weight_variable(Weights_shape)\n",
    "    b_conv = weight_variable(Bias_shape)\n",
    "    if activation == True:\n",
    "        h_conv = tf.nn.relu(conv2d(Input, w_conv, n_strides, padding) + b_conv)\n",
    "    else:\n",
    "        h_conv = conv2d(Input, w_conv, n_strides, padding) + b_conv\n",
    "    return h_conv, w_conv, b_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Primary_caps(nn_batch,Inputs, n_convcaps, n_channels, kernel_size, n_strides, padding):\n",
    "    h_conv, W_conv, b_conv = cnn_layer(Inputs, kernel_size, [n_convcaps*n_channels], n_strides, padding, activation='False')\n",
    "    q=tf.shape(Inputs)\n",
    "    caps_outs = tf.reshape(h_conv, (nn_batch,-1 , n_convcaps))#(Inputs.shape[0], -1 , n_convcaps))\n",
    "    #caps_outs = tf.reshape(h_conv, [(Inputs.shape)[0], -1, n_convcaps])\n",
    "    return h_conv, caps_outs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squashing_func(vector, axis=-1):\n",
    "    sq_norm = tf.reduce_sum(tf.square(vector),2, keep_dims=True);\n",
    "    #print \"!!!!!!!!\", sq_norm.shape\n",
    "    first_eq = sq_norm/(1+sq_norm);\n",
    "    second_eq = vector / tf.sqrt(sq_norm);\n",
    "    return first_eq*second_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digcaps(Input, o_size, v_len):\n",
    "    print \"IIshape\", Input.shape\n",
    "    r_Input = tf.reshape(Input, [(Input.shape)[0], -1, 1, (Input.shape)[2]])\n",
    "    b_I = tf.constant(np.zeros([1, Input.shape[1].value, o_size, 1], dtype=np.float32))\n",
    "    print r_Input.shape, b_I.shape\n",
    "    W = weight_variable([1, 1152, 10, 8, 16])\n",
    "    print W.shape\n",
    "    t_Input = tf.tile(Input,[1, 1, 10])\n",
    "    W= tf.tile(W, [Input.shape[0], 1, 1, 1, 1])\n",
    "    print t_Input.shape\n",
    "    print W.shape\n",
    "    return r_Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.framework.ops.reset_default_graph>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!! (50, 10, 16, 1)\n",
      "step 0, training accuracy 0.1\n",
      "step 50, training accuracy 0.28\n",
      "step 100, training accuracy 0.52\n",
      "step 150, training accuracy 0.46\n",
      "step 200, training accuracy 0.66\n",
      "step 250, training accuracy 0.62\n",
      "step 300, training accuracy 0.78\n",
      "step 350, training accuracy 0.5\n",
      "step 400, training accuracy 0.6\n",
      "step 450, training accuracy 0.66\n",
      "step 500, training accuracy 0.68\n",
      "step 550, training accuracy 0.66\n",
      "step 600, training accuracy 0.6\n",
      "step 650, training accuracy 0.62\n",
      "step 700, training accuracy 0.76\n",
      "step 750, training accuracy 0.66\n",
      "step 800, training accuracy 0.78\n",
      "step 850, training accuracy 0.54\n",
      "step 900, training accuracy 0.68\n",
      "step 950, training accuracy 0.72\n",
      "step 1000, training accuracy 0.78\n",
      "step 1050, training accuracy 0.76\n",
      "step 1100, training accuracy 0.74\n",
      "step 1150, training accuracy 0.7\n",
      "step 1200, training accuracy 0.7\n",
      "step 1250, training accuracy 0.64\n",
      "step 1300, training accuracy 0.72\n",
      "step 1350, training accuracy 0.68\n",
      "step 1400, training accuracy 0.74\n",
      "step 1450, training accuracy 0.78\n",
      "step 1500, training accuracy 0.76\n",
      "step 1550, training accuracy 0.68\n",
      "step 1600, training accuracy 0.84\n",
      "step 1650, training accuracy 0.88\n",
      "step 1700, training accuracy 0.84\n",
      "step 1750, training accuracy 0.86\n",
      "step 1800, training accuracy 0.7\n",
      "step 1850, training accuracy 0.88\n",
      "step 1900, training accuracy 0.8\n",
      "step 1950, training accuracy 0.78\n",
      "step 2000, training accuracy 0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9547b74aa29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m                                                          y_:batch[1]})\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step %d, training accuracy %g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \"\"\"\n\u001b[0;32m-> 2042\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4488\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4489\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4490\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn_batch = 50;\n",
    "nn_routing = 3;\n",
    "cfg = tf.app.flags.FLAGS\n",
    "tf.Session.reset\n",
    "with tf.device('/cpu:0'): #or '/cpu:0' for cpu only\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])    \n",
    "    h_conv1, W_conv1, b_conv1 = cnn_layer(x_image, [9, 9, 1, 256], [256], 1, padding='VALID')\n",
    "    #h_conv, W_conv, b_conv = cnn_layer(h_conv1, [9, 9, 256, 32*8], [32*8], 2, padding='VALID', activation='False')\n",
    "    h_pout, prim_caps = Primary_caps(nn_batch, h_conv1, 8, 32, [9, 9, 256, 32*8], 2,padding='VALID')\n",
    "    primarycps_s= squashing_func(prim_caps);\n",
    "    #digitCaps = digcaps(primarycaps_squashed, 10, 16);\n",
    "    #h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    #b_ij = tf.constant(0, shape = [1, 10, 10, 1,1])\n",
    "    #c = tf.nn.softmax(b_ij, dim =2)\n",
    "    #print primarycps_s.shape[-2].value\n",
    "    primarycps_s2 = tf.reshape(primarycps_s, shape=(nn_batch, -1, 1, primarycps_s.shape[-1].value))\n",
    "    bs = tf.constant(np.zeros([1, 1152, 10, 1, 1], dtype=np.float32))\n",
    "    W = weight_variable([1, 1152, 10, 8, 16])\n",
    "    W = tf.tile(W, [nn_batch, 1, 1, 1, 1])\n",
    "    \n",
    "    inputs_expanded = tf.expand_dims(tf.expand_dims(primarycps_s, 3), 2)\n",
    "    \n",
    "    primarycps_s3 = tf.tile(inputs_expanded, [1, 1, 10, 1, 1])\n",
    "    \n",
    "    u_hat = tf.matmul(W, primarycps_s3, transpose_a=True)\n",
    "    \n",
    "    for r in range(nn_routing):\n",
    "        sft_max = tf.nn.softmax(bs, dim=2)\n",
    "        sft_max = tf.tile(sft_max, [nn_batch, 1, 1,1, 1])\n",
    "        \n",
    "        mlt_sft_hat = tf.multiply(sft_max, u_hat)\n",
    "        mlt_sft_hat = tf.reduce_sum(mlt_sft_hat, axis=1, keep_dims=True)\n",
    "        \n",
    "        squash_mlt = squashing_func(mlt_sft_hat)\n",
    "        \n",
    "        squash_mlt_r = tf.tile(squash_mlt, [1, 1152, 1, 1, 1])\n",
    "        u_hat_v = tf.matmul(u_hat, squash_mlt_r, transpose_a=True)\n",
    "        bs += tf.reduce_sum(u_hat_v, axis=0, keep_dims=True)\n",
    "       \n",
    "    \n",
    "    squash_mlt = tf.squeeze(squash_mlt, axis=1)\n",
    "    #Masking\n",
    "    \n",
    "    length_v = tf.sqrt(tf.reduce_sum(tf.square(squash_mlt), axis = 2,\n",
    "                                    keep_dims = True)+1e-9)\n",
    "    print \"!!!!!!!!\", squash_mlt.shape\n",
    "    \n",
    "    softmax_v = tf.nn.softmax(length_v, dim=1)\n",
    "    argmax_idx = tf.to_int32(tf.argmax(softmax_v, axis = 1))\n",
    "    argmax_idx = tf.reshape(argmax_idx, shape=(nn_batch,))\n",
    "    y_=tf.to_float(y_)\n",
    "    if not True:\n",
    "        masked_vector = []\n",
    "        for btch in range(nn_batch):\n",
    "            v = squash_mlt[btch][argmax_idx[btch], :]\n",
    "            masked_vector.append(tf.reshape(v, shape=(1,1,16,1)))\n",
    "        masked_vector = tf.concat(masked_vector, axis=0)\n",
    "       # print masked_vector.shape\n",
    "    else:\n",
    "        y_=tf.to_float(y_)\n",
    "       # print y_.dtype\n",
    "        masked_vector = tf.matmul(tf.squeeze(squash_mlt),\n",
    "                                 tf.reshape(y_, (-1, 10, 1)), transpose_a=True)\n",
    "        length_v = tf.sqrt(tf.reduce_sum(tf.square(squash_mlt), axis=2,\n",
    "                                        keep_dims = True)+1e-9)\n",
    "    #Decoder\n",
    "    vector_j = tf.reshape(masked_vector, shape=(nn_batch, -1))\n",
    "    W_fc1 = weight_variable([16, 512])\n",
    "    b_fc1 = bias_variable([512])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(vector_j, W_fc1) + b_fc1)\n",
    "    \n",
    "    W_fc2 = weight_variable([512, 1024])\n",
    "    b_fc2 = bias_variable([1024])\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "    W_fc3 = weight_variable([1024, 784])\n",
    "    b_fc3 = bias_variable([784])\n",
    "    h_fc3 = tf.nn.sigmoid(tf.matmul(h_fc2, W_fc3) + b_fc3)\n",
    "    \n",
    "    recons_img = tf.reshape(h_fc3, shape=(nn_batch,28,28,1))\n",
    "    #print h_fc3.shape, recons_img.shape\n",
    "    #print length_v[0][:], y[0]\n",
    "    \n",
    "    #l_function = margin_loss(y_, h_fc3)\n",
    "    max_L1 = tf.square(tf.maximum(0., 0.9 - length_v))\n",
    "    max_L2 = tf.square(tf.maximum(0., length_v-0.1))\n",
    "    max_L1 = tf.reshape(max_L1, shape=(nn_batch, -1))\n",
    "    max_L2 = tf.reshape(max_L2, shape=(nn_batch, -1))   \n",
    "    lambda_t = 0.5*(1-y_)\n",
    "    Lc = y_*max_L1+lambda_t*max_L2\n",
    "    margin_loss = tf.reduce_mean((tf.reduce_sum(Lc, axis=1)))\n",
    "    \n",
    "    rec_loss = tf.reshape(x, shape=(nn_batch, -1))\n",
    "    rec_squared = tf.square(h_fc3-rec_loss)\n",
    "    rec_error = tf.reduce_mean(rec_squared)\n",
    "    \n",
    "    total_loss = margin_loss + 0.0005*rec_error\n",
    "    #print max_L1.shape, max_L2.shape, lambda_t.shape, Lc.shape\n",
    "    #print margin_loss, total_loss\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(total_loss)\n",
    "    \n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(tf.reshape(length_v, shape=(nn_batch, -1)), 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    #global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    with tf.Session(config = tf.ConfigProto(allow_soft_placement = True, log_device_placement = True)) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "     #       x = mnist.train.images[0:nn_batch]\n",
    "     #       y_ = mnist.train.labels[0:nn_batch]\n",
    "     #       xx = x_image\n",
    "     #       hh = h_conv1\n",
    "     #       h_pouts = h_pout\n",
    "     #       prim = prim_caps\n",
    "     #       squashed = primarycps_s\n",
    "     #       bb = bs;\n",
    "     #       ww = W;\n",
    "     #       expanded = inputs_expanded\n",
    "     #       p_s3 = primarycps_s3\n",
    "     #       mult_u_hat = u_hat\n",
    "     #       sft_max_s = sft_max \n",
    "     #       after_routing = squash_mlt\n",
    "     #       what_is = length_v\n",
    "\n",
    "   # print \"Input image shape\", x.shape\n",
    "   # print \"Input label shape\", y_.shape\n",
    "   # print \"Output of first convolutional layer shape\", hh.shape\n",
    "   # print \"Output of the first layer\", h_pouts.shape\n",
    "   # print \"Reshaped output of the first layer\", prim.shape\n",
    "   # print \"squashed output of the first layer\", primarycps_s.shape\n",
    "   # print \"bias for the routing\", bb.shape\n",
    "   # print \"weight for routing\", ww.shape\n",
    "   # print \"expanded inputs\", expanded.shape\n",
    "   # print \"expand the inputs for the 10 outputs\", p_s3.shape\n",
    "   # print \"u_hat\", mult_u_hat.shape\n",
    "   # print \"softmax shape\", sft_max_s.shape\n",
    "   # print \"after routing shape\", after_routing.shape\n",
    "   # print what_is.shape\n",
    "       # for step in tqdm(range(200)):\n",
    "       #     batchi = mnist.train.next_batch(50)\n",
    "       #     sess.run(train_step, feed_dict={x: batchi[0], y_: batchi[1]})\n",
    "        for i in range(5000):\n",
    "           # print i\n",
    "            batch = mnist.train.next_batch(nn_batch)\n",
    "      #     print batch\n",
    "            feed_dict={x: batch[0], y_: batch[1]}\n",
    "           # print feed_dict\n",
    "            if i%50 ==0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={x:batch[0],\n",
    "                                                         y_:batch[1]})\n",
    "                print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            train_step.run(feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1152/36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "if not True:\n",
    "    print 1\n",
    "else:\n",
    "    print 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        x = mnist.train.images[0:nn_batch]\n",
    "        y_ = mnist.train.labels[0:nn_batch]\n",
    "        xx = x_image\n",
    "        hh = h_conv1\n",
    "        h_pouts = h_pout\n",
    "        prim = prim_caps\n",
    "        squashed = primarycps_s\n",
    "        bb = bs;\n",
    "        ww = W;\n",
    "        expanded = inputs_expanded\n",
    "        p_s3 = primarycps_s3\n",
    "        mult_u_hat = u_hat\n",
    "        sft_max_s = sft_max \n",
    "        after_routing = squash_mlt\n",
    "        what_is = length_v\n",
    "\n",
    "print \"Input image shape\", x.shape\n",
    "print \"Input label shape\", y_.shape\n",
    "print \"Output of first convolutional layer shape\", hh.shape\n",
    "print \"Output of the first layer\", h_pouts.shape\n",
    "print \"Reshaped output of the first layer\", prim.shape\n",
    "print \"squashed output of the first layer\", primarycps_s.shape\n",
    "print \"bias for the routing\", bb.shape\n",
    "print \"weight for routing\", ww.shape\n",
    "print \"expanded inputs\", expanded.shape\n",
    "print \"expand the inputs for the 10 outputs\", p_s3.shape\n",
    "print \"u_hat\", mult_u_hat.shape\n",
    "print \"softmax shape\", sft_max_s.shape\n",
    "print \"after routing shape\", after_routing.shape\n",
    "print what_is.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
