{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deffining our initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    w_h = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(w_h)\n",
    "def bias_variable(shape):\n",
    "    b_h = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deffining useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(Input, Weights):\n",
    "    return tf.nn.conv2d(Input, Weights, strides = [1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "def max_pool_2x2(Input):\n",
    "    return tf.nn.max_pool(Input, ksize = [1, 2, 2, 1],\n",
    "                         strides = [1, 2, 2, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_layer(Input, Weights_shape, Bias_shape):\n",
    "    w_conv = weight_variable(Weights_shape)\n",
    "    b_conv = weight_variable(Bias_shape)\n",
    "    h_conv = tf.nn.relu(conv2d(Input, w_conv) + b_conv)\n",
    "    return h_conv, w_conv, b_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs = conv output\n",
    "#n_convcaps = 8\n",
    "#n_channels = 32\n",
    "#kernel_size = 9\n",
    "#n_strides = 2\n",
    "#padding = 'valid' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(Input, Weights, n_strides=2, padding='SAME'):\n",
    "    return tf.nn.conv2d(Input, Weights, strides = [1, n_strides, n_strides, 1], padding=padding)\n",
    "def max_pool_2x2(Input):\n",
    "    return tf.nn.max_pool(Input, ksize = [1, 2, 2, 1],\n",
    "                         strides = [1, 2, 2, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_layer(Input, Weights_shape, Bias_shape, n_strides, padding, activation=True):\n",
    "    w_conv = weight_variable(Weights_shape)\n",
    "    b_conv = weight_variable(Bias_shape)\n",
    "    if activation == True:\n",
    "        h_conv = tf.nn.relu(conv2d(Input, w_conv, n_strides, padding) + b_conv)\n",
    "    else:\n",
    "        h_conv = conv2d(Input, w_conv, n_strides, padding) + b_conv\n",
    "    return h_conv, w_conv, b_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Primary_caps(Inputs, n_convcaps, n_channels, kernel_size, n_strides, padding):\n",
    "    h_conv, W_conv, b_conv = cnn_layer(Inputs, kernel_size, [n_convcaps*n_channels], n_strides, padding, activation='False')\n",
    "    q=tf.shape(Inputs)\n",
    "    caps_outs = tf.reshape(h_conv, (2,-1 , n_convcaps))#(Inputs.shape[0], -1 , n_convcaps))\n",
    "    #caps_outs = tf.reshape(h_conv, [(Inputs.shape)[0], -1, n_convcaps])\n",
    "    return h_conv, caps_outs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squashing_func(vector, axis=-1):\n",
    "    sq_norm = tf.reduce_sum(tf.square(vector),0, keep_dims=True);\n",
    "    first_eq = sq_norm/(1+sq_norm);\n",
    "    second_eq = vector / tf.sqrt(sq_norm);\n",
    "    return first_eq*second_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digcaps(Input, o_size, v_len):\n",
    "    print Input.shape\n",
    "    r_Input = tf.reshape(Input, [(Input.shape)[0], -1, 1, (Input.shape)[2]])\n",
    "    b_I = tf.constant(np.zeros([1, Input.shape[1].value, o_size, 1], dtype=np.float32))\n",
    "    print r_Input.shape, b_I.shape\n",
    "    W = weight_variable([1, 1152, 10, 8, 16])\n",
    "    print W.shape\n",
    "    t_Input = tf.tile(Input,[1, 1, 10])\n",
    "    W= tf.tile(W, [Input.shape[0], 1, 1, 1, 1])\n",
    "    print t_Input.shape\n",
    "    print W.shape\n",
    "    return r_Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (2, 10, 16, 1)\n",
      "Input shape (2, 784)\n",
      "Output of first convolutional layer shape (2, 20, 20, 256)\n",
      "Output of the first layer (2, 6, 6, 256)\n",
      "Reshaped output of the first layer (2, 1152, 8)\n",
      "squashed output of the first layer (2, 1152, 8)\n",
      "bias for the routing (1, 1152, 10, 1, 1)\n",
      "weight for routing (2, 1152, 10, 8, 16)\n",
      "expanded inputs (2, 1152, 1, 8, 1)\n",
      "expand the inputs for the 10 outputs (2, 1152, 10, 8, 1)\n",
      "u_hat (2, 1152, 10, 16, 1)\n",
      "softmax shape (2, 1152, 10, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg = tf.app.flags.FLAGS\n",
    "tf.Session.reset\n",
    "with tf.device('/gpu:1'): #or '/cpu:0' for cpu only\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])    \n",
    "    h_conv1, W_conv1, b_conv1 = cnn_layer(x_image, [9, 9, 1, 256], [256], 1, padding='VALID')\n",
    "    #h_conv, W_conv, b_conv = cnn_layer(h_conv1, [9, 9, 256, 32*8], [32*8], 2, padding='VALID', activation='False')\n",
    "    h_pout, prim_caps = Primary_caps(h_conv1, 8, 32, [9, 9, 256, 32*8], 2,padding='VALID')\n",
    "    primarycps_s= squashing_func(prim_caps);\n",
    "    #digitCaps = digcaps(primarycaps_squashed, 10, 16);\n",
    "    #h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    #b_ij = tf.constant(0, shape = [1, 10, 10, 1,1])\n",
    "    #c = tf.nn.softmax(b_ij, dim =2)\n",
    "    #print primarycps_s.shape[-2].value\n",
    "    primarycps_s2 = tf.reshape(primarycps_s, shape=(2, -1, 1, primarycps_s.shape[-1].value))\n",
    "    #print primarycps_s2\n",
    "    bs = tf.constant(np.zeros([1, 1152, 10, 1, 1], dtype=np.float32))\n",
    "    W = weight_variable([1, 1152, 10, 8, 16])\n",
    "    W = tf.tile(W, [2, 1, 1, 1, 1])\n",
    "    \n",
    "    inputs_expanded = tf.expand_dims(tf.expand_dims(primarycps_s, 3), 2)\n",
    "    primarycps_s3 = tf.tile(inputs_expanded, [1, 1, 10, 1, 1])\n",
    "    \n",
    "    u_hat = tf.matmul(W, primarycps_s3, transpose_a=True)\n",
    "    \n",
    "    for r in range(3):\n",
    "        sft_max = tf.nn.softmax(bs, dim=2)\n",
    "        sft_max = tf.tile(sft_max, [2, 1, 1, 1, 1])\n",
    "        mlt_sft_hat = tf.multiply(sft_max, u_hat)\n",
    "        mlt_sft_hat = tf.reduce_sum(mlt_sft_hat, axis=1, keep_dims=True)\n",
    "        squash_mlt = squashing_func(mlt_sft_hat)\n",
    "        \n",
    "        squash_mlt_r = tf.tile(squash_mlt, [1, 1152, 1, 1, 1])\n",
    "        u_hat_v = tf.matmul(u_hat, squash_mlt_r, transpose_a=True)\n",
    "        \n",
    "        bs += tf.reduce_sum(u_hat_v, axis=0, keep_dims=True)\n",
    "       \n",
    "    \n",
    "    squash_mlt = tf.squeeze(squash_mlt, axis=1)\n",
    "    print \"shape\", squash_mlt.shape\n",
    "    \n",
    "    with tf.Session(config = tf.ConfigProto(allow_soft_placement = True, log_device_placement = True)) as sess:\n",
    "        \n",
    "        x = mnist.train.images[0:2]\n",
    "        xx = x_image\n",
    "        hh = h_conv1\n",
    "        h_pouts = h_pout\n",
    "        prim = prim_caps\n",
    "        squashed = primarycps_s\n",
    "        bb = bs;\n",
    "        ww = W;\n",
    "        expanded = inputs_expanded\n",
    "        p_s3 = primarycps_s3\n",
    "        mult_u_hat = u_hat\n",
    "        sft_max_s = sft_max \n",
    "        #bj = b_ij\n",
    "print \"Input shape\", x.shape\n",
    "print \"Output of first convolutional layer shape\", hh.shape\n",
    "print \"Output of the first layer\", h_pouts.shape\n",
    "print \"Reshaped output of the first layer\", prim.shape\n",
    "print \"squashed output of the first layer\", primarycps_s.shape\n",
    "print \"bias for the routing\", bb.shape\n",
    "print \"weight for routing\", ww.shape\n",
    "print \"expanded inputs\", expanded.shape\n",
    "print \"expand the inputs for the 10 outputs\", p_s3.shape\n",
    "print \"u_hat\", mult_u_hat.shape\n",
    "print \"softmax shape\", sft_max_s.shape\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 784)\n",
      "(2, 28, 28, 1)\n",
      "(2, 6, 6, 256)\n",
      "(2, 20, 20, 256)\n",
      "(2, 1152, 8)\n",
      "(1, 10, 10, 1, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sqhd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a78a6eff0837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0msqhd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sqhd' is not defined"
     ]
    }
   ],
   "source": [
    "print x.shape\n",
    "print xx.shape\n",
    "print h_pouts.shape\n",
    "print h_conv1.shape\n",
    "print prim.shape\n",
    "print bj.shape\n",
    "print sqhd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.array_ops.shape>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
